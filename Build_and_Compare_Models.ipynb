{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Compare the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to print out the results for each model\n",
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tr_features = pd.read_csv('train_features.csv')\n",
    "tr_labels = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Fit and evaluate a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 1}\n",
      "\n",
      "0.672 (+/-0.06) for {'C': 0.001}\n",
      "0.706 (+/-0.064) for {'C': 0.01}\n",
      "0.788 (+/-0.09) for {'C': 0.1}\n",
      "0.813 (+/-0.063) for {'C': 1}\n",
      "0.813 (+/-0.063) for {'C': 10}\n",
      "0.813 (+/-0.063) for {'C': 100}\n",
      "0.813 (+/-0.063) for {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "lrcv = GridSearchCV(lr, parameters, cv=5)\n",
    "lrcv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(lrcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save best model\n",
    "joblib.dump(lrcv.best_estimator_, 'LR_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines: Fit and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.809 (+/-0.032) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.665 (+/-0.06) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.809 (+/-0.032) for {'C': 1, 'kernel': 'linear'}\n",
      "0.672 (+/-0.073) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.809 (+/-0.032) for {'C': 10, 'kernel': 'linear'}\n",
      "0.695 (+/-0.069) for {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "svmcv = GridSearchCV(svc, parameters, cv=5)\n",
    "svmcv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(svmcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save best model\n",
    "joblib.dump(svmcv.best_estimator_, 'SVM_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron: Fit and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "\n",
      "0.788 (+/-0.082) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.76 (+/-0.179) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.802 (+/-0.067) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.798 (+/-0.082) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.777 (+/-0.106) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.798 (+/-0.073) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.764 (+/-0.098) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.786 (+/-0.076) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.792 (+/-0.097) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.796 (+/-0.068) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.809 (+/-0.06) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.805 (+/-0.08) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.803 (+/-0.075) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.809 (+/-0.084) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.8 (+/-0.08) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.802 (+/-0.098) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.792 (+/-0.095) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.798 (+/-0.099) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n",
      "0.792 (+/-0.098) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant'}\n",
      "0.803 (+/-0.073) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling'}\n",
      "0.803 (+/-0.085) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive'}\n",
      "0.79 (+/-0.065) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "0.798 (+/-0.099) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling'}\n",
      "0.796 (+/-0.076) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive'}\n",
      "0.777 (+/-0.09) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "0.798 (+/-0.096) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling'}\n",
      "0.785 (+/-0.087) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickseletto/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "\n",
    "mlpcv = GridSearchCV(mlp, parameters, cv=5)\n",
    "mlpcv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(mlpcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLP_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save best model\n",
    "joblib.dump(mlpcv.best_estimator_, 'MLP_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: Fit and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 4, 'n_estimators': 250}\n",
      "\n",
      "0.788 (+/-0.067) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.815 (+/-0.037) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.818 (+/-0.057) for {'max_depth': 2, 'n_estimators': 250}\n",
      "0.813 (+/-0.073) for {'max_depth': 4, 'n_estimators': 5}\n",
      "0.848 (+/-0.038) for {'max_depth': 4, 'n_estimators': 50}\n",
      "0.852 (+/-0.039) for {'max_depth': 4, 'n_estimators': 250}\n",
      "0.803 (+/-0.06) for {'max_depth': 8, 'n_estimators': 5}\n",
      "0.83 (+/-0.027) for {'max_depth': 8, 'n_estimators': 50}\n",
      "0.831 (+/-0.039) for {'max_depth': 8, 'n_estimators': 250}\n",
      "0.811 (+/-0.084) for {'max_depth': 16, 'n_estimators': 5}\n",
      "0.822 (+/-0.031) for {'max_depth': 16, 'n_estimators': 50}\n",
      "0.83 (+/-0.014) for {'max_depth': 16, 'n_estimators': 250}\n",
      "0.8 (+/-0.03) for {'max_depth': 32, 'n_estimators': 5}\n",
      "0.83 (+/-0.014) for {'max_depth': 32, 'n_estimators': 50}\n",
      "0.824 (+/-0.021) for {'max_depth': 32, 'n_estimators': 250}\n",
      "0.805 (+/-0.048) for {'max_depth': None, 'n_estimators': 5}\n",
      "0.82 (+/-0.035) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.82 (+/-0.014) for {'max_depth': None, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None]\n",
    "}\n",
    "\n",
    "rfcv = GridSearchCV(rf, parameters, cv=5)\n",
    "rfcv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(rfcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RF_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save best model\n",
    "joblib.dump(rfcv.best_estimator_, \"RF_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting: Fit and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "\n",
      "0.618 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.809 (+/-0.032) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.809 (+/-0.032) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.826 (+/-0.032) for {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.618 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.818 (+/-0.042) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.845 (+/-0.065) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.85 (+/-0.057) for {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.618 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.82 (+/-0.069) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.841 (+/-0.04) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.835 (+/-0.055) for {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.618 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.83 (+/-0.066) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.822 (+/-0.074) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.816 (+/-0.065) for {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.618 (+/-0.005) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.83 (+/-0.097) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.811 (+/-0.055) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.801 (+/-0.045) for {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.809 (+/-0.032) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.826 (+/-0.032) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.83 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.831 (+/-0.052) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.818 (+/-0.042) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.843 (+/-0.06) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.848 (+/-0.048) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.837 (+/-0.03) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.818 (+/-0.078) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.837 (+/-0.059) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.815 (+/-0.046) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.811 (+/-0.048) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.826 (+/-0.075) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.818 (+/-0.065) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.811 (+/-0.063) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.813 (+/-0.055) for {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.822 (+/-0.099) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.809 (+/-0.067) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.807 (+/-0.05) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.809 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.803 (+/-0.082) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.835 (+/-0.051) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.833 (+/-0.044) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.82 (+/-0.054) for {'learning_rate': 1, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.837 (+/-0.042) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.824 (+/-0.041) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.807 (+/-0.054) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.811 (+/-0.038) for {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.809 (+/-0.074) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.833 (+/-0.018) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.816 (+/-0.033) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.807 (+/-0.026) for {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.798 (+/-0.066) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.811 (+/-0.035) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.815 (+/-0.038) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.813 (+/-0.033) for {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.794 (+/-0.065) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.807 (+/-0.073) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.811 (+/-0.025) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.811 (+/-0.021) for {'learning_rate': 1, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.191 (+/-0.032) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.191 (+/-0.032) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.191 (+/-0.032) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.191 (+/-0.032) for {'learning_rate': 10, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.387 (+/-0.372) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.389 (+/-0.373) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.389 (+/-0.373) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.387 (+/-0.372) for {'learning_rate': 10, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.485 (+/-0.217) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.479 (+/-0.224) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.468 (+/-0.243) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.485 (+/-0.219) for {'learning_rate': 10, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.483 (+/-0.212) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.496 (+/-0.201) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.485 (+/-0.201) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.494 (+/-0.202) for {'learning_rate': 10, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.687 (+/-0.126) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.693 (+/-0.147) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.7 (+/-0.133) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.693 (+/-0.155) for {'learning_rate': 10, 'max_depth': 9, 'n_estimators': 500}\n",
      "0.382 (+/-0.005) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 5}\n",
      "0.382 (+/-0.005) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 50}\n",
      "0.382 (+/-0.005) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 250}\n",
      "0.382 (+/-0.005) for {'learning_rate': 100, 'max_depth': 1, 'n_estimators': 500}\n",
      "0.283 (+/-0.194) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 5}\n",
      "0.283 (+/-0.194) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.283 (+/-0.194) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 250}\n",
      "0.283 (+/-0.194) for {'learning_rate': 100, 'max_depth': 3, 'n_estimators': 500}\n",
      "0.335 (+/-0.218) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 5}\n",
      "0.38 (+/-0.137) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 50}\n",
      "0.386 (+/-0.149) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 250}\n",
      "0.378 (+/-0.149) for {'learning_rate': 100, 'max_depth': 5, 'n_estimators': 500}\n",
      "0.397 (+/-0.226) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 5}\n",
      "0.371 (+/-0.214) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 50}\n",
      "0.393 (+/-0.193) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 250}\n",
      "0.38 (+/-0.228) for {'learning_rate': 100, 'max_depth': 7, 'n_estimators': 500}\n",
      "0.599 (+/-0.131) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 5}\n",
      "0.588 (+/-0.127) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 50}\n",
      "0.554 (+/-0.126) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 250}\n",
      "0.569 (+/-0.129) for {'learning_rate': 100, 'max_depth': 9, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "gbcv = GridSearchCV(gb, parameters, cv=5)\n",
    "gbcv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(gbcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save best model\n",
    "joblib.dump(gbcv.best_estimator_, \"GB_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to output the evaluation metrics\n",
    "def evaluate_model(name, model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred), 3)\n",
    "    recall = round(recall_score(labels, pred), 3)\n",
    "    print('{} -- Accuracy: {} / Precision: {} / Recall: {} / Latency: {}ms'.format(name,\n",
    "                                                                                   accuracy,\n",
    "                                                                                   precision,\n",
    "                                                                                   recall,\n",
    "                                                                                   round((end - start)*1000, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from time import time\n",
    "\n",
    "val_features = pd.read_csv('val_features.csv')\n",
    "val_labels = pd.read_csv('val_labels.csv')\n",
    "\n",
    "te_features = pd.read_csv('test_features.csv')\n",
    "te_labels = pd.read_csv('test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the models to compare\n",
    "models = {} \n",
    "\n",
    "for mdl in ['LR', 'SVM', 'MLP', 'RF', 'GB']:\n",
    "    models[mdl] = joblib.load(\"{}_model.pkl\".format(mdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR -- Accuracy: 0.803 / Precision: 0.82 / Recall: 0.676 / Latency: 1.6ms\n",
      "SVM -- Accuracy: 0.747 / Precision: 0.746 / Recall: 0.595 / Latency: 1.7ms\n",
      "MLP -- Accuracy: 0.809 / Precision: 0.823 / Recall: 0.689 / Latency: 1.6ms\n",
      "RF -- Accuracy: 0.798 / Precision: 0.828 / Recall: 0.649 / Latency: 31.8ms\n",
      "GB -- Accuracy: 0.787 / Precision: 0.833 / Recall: 0.608 / Latency: 2.4ms\n"
     ]
    }
   ],
   "source": [
    "#Test the models on the validation data\n",
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, val_features, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron -- Accuracy: 0.771 / Precision: 0.683 / Recall: 0.672 / Latency: 1.7ms\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the best model on the test data\n",
    "evaluate_model('Multilayer Perceptron', models['MLP'], te_features, te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
